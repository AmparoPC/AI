!wget --no-check-certificate \
    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \
    -O /tmp/sarcasm.json
  
import json  #permite descargar la informacion en formato json y estructurarlo en formato python

with open("/tmp/sarcasm.json", 'r') as f: 
    datastore = json.load(f)     #carga el codigo de kaggle que permite saber si un articulo es sarcástico o no


sentences = [] 
labels = []
urls = []
for item in datastore:
    sentences.append(item['headline'])
    labels.append(item['is_sarcastic'])
    urls.append(item['article_link'])



from tensorflow.keras.preprocessing.text import Tokenizer #API tokenizer permite dar valores a las palabras, no distingue mayus/minus ni signos puntuacion
from tensorflow.keras.preprocessing.sequence import pad_sequences #para ajustar el tamaño de las frases
tokenizer = Tokenizer(oov_token="<OOV>") #añade 'out of vocabulary' cuando la palabra no ha sido vista anteriormente
tokenizer.fit_on_texts(sentences)  #accion del tokenizer

word_index = tokenizer.word_index #devuelve lista valores de palabra y código
print(len(word_index)) 
print(word_index)
sequences = tokenizer.texts_to_sequences(sentences)  #transforma las frases en secuencias de numeros
padded = pad_sequences(sequences, padding='post')  #ajusta el tamaño para que todas sean del mismo tamaño
print(padded[0]) #imprime la primera frase
print(padded.shape) # filas columnas matriz (numero de frases y su longitud)
